{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Loading corpus and queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"clarin-knext/fiqa-pl\", \"corpus\")\n",
    "ds2 = load_dataset(\"clarin-knext/fiqa-pl\", \"queries\")\n",
    "corpus = ds['corpus'].to_pandas()\n",
    "queries = ds2['queries'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Co jest uważane za wydatek służbowy w podróży ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>Wydatki służbowe - ubezpieczenie samochodu pod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>Rozpoczęcie nowego biznesu online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>„Dzień roboczy” i „termin płatności” rachunków</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>Nowy właściciel firmy – Jak działają podatki d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _id title                                               text\n",
       "0   0        Co jest uważane za wydatek służbowy w podróży ...\n",
       "1   4        Wydatki służbowe - ubezpieczenie samochodu pod...\n",
       "2   5                        Rozpoczęcie nowego biznesu online\n",
       "3   6           „Dzień roboczy” i „termin płatności” rachunków\n",
       "4   7        Nowy właściciel firmy – Jak działają podatki d..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Creating a dataset of positive and negative sentence pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will load the dataset that conects queries with corpus by id, question and answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['query-id', 'corpus-id', 'score'],\n",
       "        num_rows: 14166\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['query-id', 'corpus-id', 'score'],\n",
       "        num_rows: 1238\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['query-id', 'corpus-id', 'score'],\n",
       "        num_rows: 1706\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds3 = load_dataset(\"clarin-knext/fiqa-pl-qrels\")\n",
    "ds3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = ds3['validation'].to_pandas()\n",
    "train = ds3['train'].to_pandas()\n",
    "test = ds3['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>308938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>296717</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>314352</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query-id  corpus-id  score\n",
       "0         1      14255      1\n",
       "1         2     308938      1\n",
       "2         3     296717      1\n",
       "3         3     100764      1\n",
       "4         3     314352      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's see the question and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Zgłaszanie wydatków biznesowych dla firmy bez dochodu\n",
      "Answer:  Tak, możesz ubiegać się o potrącenia biznesowe, jeśli nie uzyskujesz jeszcze żadnych dochodów. Ale najpierw powinieneś zdecydować, jaką strukturę chcesz mieć dla swojej firmy. Albo struktura firmy, albo jednoosobowy przedsiębiorca lub spółka osobowa. Struktura firmy Jeśli wybierzesz strukturę firmy (która jest droższa w przygotowaniu), będziesz ubiegać się o potrącenia, ale bez dochodu. Więc ponosiłbyś stratę i kontynuowałbyś straty, dopóki dochód z firmy nie przekroczy twoich wydatków. Straty te pozostaną więc w firmie i będą mogły zostać przeniesione na przyszłe lata dochodowe, kiedy będziesz osiągać zyski, aby zrekompensować te zyski. Więcej informacji można znaleźć w ATO – Straty podatkowe firmy. Przedsiębiorca jednoosobowy o strukturze partnerskiej Jeśli zdecydujesz się być jednoosobowym przedsiębiorcą lub spółką osobową, a Twoja firma ponosi straty, musisz sprawdzić zasady dotyczące strat niekomercyjnych, aby sprawdzić, czy możesz zrównoważyć stratę z dochodami z innych źródeł, takich jak zarobki. Aby zrekompensować straty firmy z innymi dochodami, firma musi zdać jeden z tych testów: Jeśli nie zdasz żadnego z tych testów, co najprawdopodobniej nie zostanie wykonane jako start-up, musisz kontynuować działalność straty aż do roku dochodowego, w którym zdasz jeden z testów, wtedy możesz odliczyć je od innych dochodów. To właśnie odróżnia legalną firmę od kogoś, kto ma hobby, ponieważ jeśli nie zaczniesz zarabiać co najmniej 20 000 USD ze sprzedaży (najłatwiejszy test do zdawania), nie możesz wykorzystać strat biznesowych w stosunku do innych dochodów. Więcej informacji można znaleźć w ATO – Straty niekomercyjne.\n"
     ]
    }
   ],
   "source": [
    "print(\"Question: \", queries[queries['_id'] == '1']['text'].iloc[0])\n",
    "print(\"Answer: \", corpus[corpus['_id'] == '14255']['text'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7578, -0.6469],\n",
      "        [-0.7338,  1.0468]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "trained_model = True\n",
    "model_path = \"\"\n",
    "model = None\n",
    "\n",
    "if trained_model:\n",
    "    model_path = \"../trained_model\"\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_path\n",
    "        ).to(\"cuda\")\n",
    "else:\n",
    "    model_path = \"clarin-knext/herbert-base-reranker-msmarco\"\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_path\n",
    "        ).to(\"cuda\")\n",
    "    model.classifier = nn.Linear(768, 2, device=model.device)\n",
    "    model.num_labels = 2\n",
    "    model.config.num_labels = 2\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "features = tokenizer(['Jakie miasto jest stolica Polski?', 'Stolicą Polski jest Warszawa.'],  padding=True, truncation=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    scores = model(**features).logits\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separator = tokenizer.sep_token\n",
    "separator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "big_df = pd.concat([validation,train,test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sentence': 'Zgłaszanie wydatków biznesowych dla firmy bez dochodu</s>Tak, możesz ubiegać się o potrącenia biznesowe, jeśli nie uzyskujesz jeszcze żadnych dochodów. Ale najpierw powinieneś zdecydować, jaką strukturę chcesz mieć dla swojej firmy. Albo struktura firmy, albo jednoosobowy przedsiębiorca lub spółka osobowa. Struktura firmy Jeśli wybierzesz strukturę firmy (która jest droższa w przygotowaniu), będziesz ubiegać się o potrącenia, ale bez dochodu. Więc ponosiłbyś stratę i kontynuowałbyś straty, dopóki dochód z firmy nie przekroczy twoich wydatków. Straty te pozostaną więc w firmie i będą mogły zostać przeniesione na przyszłe lata dochodowe, kiedy będziesz osiągać zyski, aby zrekompensować te zyski. Więcej informacji można znaleźć w ATO – Straty podatkowe firmy. Przedsiębiorca jednoosobowy o strukturze partnerskiej Jeśli zdecydujesz się być jednoosobowym przedsiębiorcą lub spółką osobową, a Twoja firma ponosi straty, musisz sprawdzić zasady dotyczące strat niekomercyjnych, aby sprawdzić, czy możesz zrównoważyć stratę z dochodami z innych źródeł, takich jak zarobki. Aby zrekompensować straty firmy z innymi dochodami, firma musi zdać jeden z tych testów: Jeśli nie zdasz żadnego z tych testów, co najprawdopodobniej nie zostanie wykonane jako start-up, musisz kontynuować działalność straty aż do roku dochodowego, w którym zdasz jeden z testów, wtedy możesz odliczyć je od innych dochodów. To właśnie odróżnia legalną firmę od kogoś, kto ma hobby, ponieważ jeśli nie zaczniesz zarabiać co najmniej 20 000 USD ze sprzedaży (najłatwiejszy test do zdawania), nie możesz wykorzystać strat biznesowych w stosunku do innych dochodów. Więcej informacji można znaleźć w ATO – Straty niekomercyjne.',\n",
       "  'label': 1},\n",
       " {'sentence': 'Przekazywanie pieniędzy z jednej kontroli biznesowej do innej kontroli biznesowej</s>„Powinieneś mieć oddzielne pliki dla każdej z dwóch firm. Firma, która przekazuje pieniądze, powinna „„wypisać czek”” w swoim pliku QB. Firma, która otrzymuje pieniądze, powinna „„zrobić depozyt”” w swoim pliku QB. QB „wypisz czek” nawet wtedy, gdy dokonujesz płatności w inny sposób, np. ACH). Żadna firma nie powinna mieć wyraźnie reprezentowanych kont bankowych drugiej strony. Z każdej strony musisz również zaklasyfikować płatność jako pochodzącą z/przeszedł na inne konto – aby wiedzieć, co jest tam poprawne, musimy najpierw wiedzieć, dlaczego przelewasz pieniądze i w jaki sposób masz ustalone książki. Myślę, że to prawdopodobnie wykracza poza zakres tego, co jest na temat / wykonalne tutaj. Pieniądze z twojego konta osobistego są prawdopodobnie kapitałem własnym właściciela, chyba że dzieje się coś innego. Na przykład w S Corp powinieneś płacić sobie pensję. Jeśli przez przypadek przepłacisz, możesz napisać czek z powrotem do firmy z konta osobistego, aby poprawić błąd. To nie jest kapitał własny — to prawdopodobnie „wydatek ujemny” na innym koncie, które śledzi wypłaty wynagrodzenia”.',\n",
       "  'label': 1},\n",
       " {'sentence': 'Posiadanie oddzielnego konta bankowego do prowadzenia działalności/inwestowania, ale nie „konta firmowego”?</s>„Posiadanie oddzielnego konta czekowego dla firmy ma sens. Ułatwia to dokumentowanie dochodów/wydatków. Możesz „wyjaśnić” każdy dolar wchodzący i wychodzący z konta bez konieczności pamiętania, że \\u200b\\u200bniektóre z nich były przeznaczone na pozycje niebiznesowe. Unia kredytowa pozwoliła mi mieć drugie konto czekowe i pozwoliła mi umieścić to, co chciałem jako imię na czeku.Myślę, że wyglądało to trochę lepiej niż posiadanie mojego imienia i nazwiska na czeku.Nie widzę potrzeby oddzielnego rachunek bieżący do inwestowania Pieniądze mogą być trzymane na oddzielnym koncie oszczędnościowym, które nie ma żadnych opłat, a nawet może trochę zarobić. Chyba że robisz dużo transakcji inwestycyjnych w miesiącu, to mi się udało. Finansuję IRA i 529 planuje w ten sposób. Otrzymujemy czeki 4-5 razy w miesiącu, ale pieniądze wysyłamy do każdego z funduszy raz w miesiącu. Będziesz potrzebować konta firmowego, jeśli liczba transakcji stanie się duża. Jeśli za każdym razem wpłacasz dziesiątki czeków do banku, bank będzie chciał się przenieść y na konto firmowe.\"',\n",
       "  'label': 1},\n",
       " {'sentence': 'Posiadanie oddzielnego konta bankowego do prowadzenia działalności/inwestowania, ale nie „konta firmowego”?</s>„Nie określasz, w jakim kraju się znajdujesz, więc moje odpowiedzi są bardziej z punktu widzenia najlepszych praktyk niż z punktu widzenia prawa. Nie zamierzam używać go do użytku osobistego, ale mam na myśli, że jest tak jak to możliwe. niebezpieczna propozycja.. Nie należy mieszać wydatków służbowych z osobistymi. Jeśli jest szansa, że \\u200b\\u200btak się stanie, przestań, zrób to tak, aby tak się nie stało. Duże niebezpieczeństwo polega na możliwości śledzenia między tym, co robisz dla firmy, a tym, co robisz dla siebie. Jeśli używasz tego konta jako „tymczasowego” konta do inwestycji itp., czy są to inwestycje dla siebie? Czy dla firmy? Czy jest to opodatkowanie na zyskach kapitałowych i/lub dywidendach są takie same dla osób prywatnych i firm w Twojej jurysdykcji? Jeśli kupisz widget, czy widget jest wydatkiem na dochód firmy? A może jest to wydatek z własnej kieszeni na konsumpcję osobistą? Ten pierwszy zmniejsza dochód podlegający opodatkowaniu , to drugie nie. Nie widzę korzyści z posiadania prawdziwego konta firmowego, ponieważ używaj tych, które mają cechy charakterystyczne dla korporacji, LLC itp. - nic korzystnego dla jedynego właściciela, który nie ma raportów / pracowników. Prawdziwą korzyścią jest to, że istnieje wyraźne rozgraniczenie między dochodami/wydatkami biznesowymi a dochodami/wydatkami osobistymi. To konto może również przyjmować pieniądze i przechowywać je z transakcji biznesowych/sprzedaży, a także ewentualnie przenosić część na konto osobiste, jeśli nie ma potrzeby reinwestowania tej kwoty/procentu. To, czego szukasz, to potocznie zwany rachunek bieżący, ponieważ służy do bieżących wydatków. Jeśli przenosisz pieniądze z konta na konto osobiste, oznacza to płacenie sobie, co ma również inne konsekwencje. Najbezpieczniejszym/najczystszym sposobem, aby to zrobić, jest: Choć może to brzmieć jak przesada, jest to jedyny sposób, aby zagwarantować, że dochody/wydatki zostaną przydzielone właściwej jednostce (tj. Tobie lub Twojej firmie). Z kanadyjskiego punktu widzenia:\"',\n",
       "  'label': 1},\n",
       " {'sentence': 'Posiadanie oddzielnego konta bankowego do prowadzenia działalności/inwestowania, ale nie „konta firmowego”?</s>Jeśli to ułatwia finanse, dlaczego nie? Moja żona i ja mieliśmy jego/jej/nasz jeszcze zanim się pobraliśmy. Mam również konto do obsługi transakcji dotyczących mojej wynajmowanej nieruchomości i jedno dodatkowe do korzystania z PayPal. Miałem paranoję, podając numer konta czekowego z upoważnieniem dla osoby trzeciej do obciążenia go, tak aby konto miało maksymalnie kilkaset dolarów. Wszystko to ma na celu wyjaśnienie, że twoje finanse powinny być tak zorganizowane, aby uprościć twoje życie i zapewnić ci wygodę.',\n",
       "  'label': 1}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_ = []\n",
    "\n",
    "for index, row in big_df.iterrows():\n",
    "\n",
    "  corpus_id = row['corpus-id']\n",
    "  query_id = row['query-id']\n",
    "\n",
    "  list_.append({\n",
    "    'sentence': queries[queries['_id'] == str(query_id)]['text'].iloc[0] + separator + corpus[corpus['_id'] == str(corpus_id)]['text'].iloc[0],\n",
    "    'label': 1\n",
    "  })\n",
    "\n",
    "list_[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17110"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in big_df.iterrows():\n",
    "\n",
    "  corpus_id = row['corpus-id']\n",
    "  query_id = row['query-id']\n",
    "\n",
    "  for i in range(3):\n",
    "    \n",
    "    index = (corpus_id + i)%len(corpus)\n",
    "    if corpus.iloc[index]['_id'] != corpus_id:\n",
    "      list_.append({\n",
    "        'sentence': queries[queries['_id'] == str(query_id)]['text'].iloc[0] + separator + corpus.iloc[index]['text'],\n",
    "        'label': 0\n",
    "      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68440"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Training a text classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe4a92316f34b62a648916418d775c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stringifying the column:   0%|          | 0/41064 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643191560c714e958664840eea4b3c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/41064 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8113da8bcf34952b3fbc6d5fa46e9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stringifying the column:   0%|          | 0/13688 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169417243297456493341a82232396c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/13688 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9366cc7294344b2e87b97753ff935a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stringifying the column:   0%|          | 0/13688 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a693cdb0ea024e4da2a6ded292506971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/13688 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "df = pd.DataFrame(list_, columns=['sentence', 'label'])\n",
    "\n",
    "temp, test = train_test_split(df, test_size=0.2, random_state=2137)\n",
    "train, eval = train_test_split(temp, test_size=0.25, random_state=2137)\n",
    "\n",
    "train = Dataset.from_pandas(train)\n",
    "train = train.class_encode_column(\"label\")\n",
    "test = Dataset.from_pandas(test)\n",
    "test = test.class_encode_column(\"label\")\n",
    "eval = Dataset.from_pandas(eval)\n",
    "eval = eval.class_encode_column(\"label\")\n",
    "\n",
    "train= train.rename_column(\"__index_level_0__\", \"input_ids\")\n",
    "test = test.rename_column(\"__index_level_0__\", \"input_ids\")\n",
    "eval = eval.rename_column(\"__index_level_0__\", \"input_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train length:  41064  Test length:  13688  Evaluation:  13688\n"
     ]
    }
   ],
   "source": [
    "print(\"Train length: \", len(train), \" Test length: \", len(test), \" Evaluation: \", len(eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Co to jest odwrócenie niedźwiedziego paska?</s>Depilacja laserowa nie jest trwała, trzeba wykonać kilka sesji, aby usunąć wszystkie włosy, każda sesja kosztuje setki. A potem może to potrwać tylko kilka lat, zanim włosy odrosną. Nie jest wart swojej ceny, chyba że masz tak dużą kwotę, że możesz wyrzucić kilka tysięcy. Jak powiedzieli inni, albo kupuj hurtowo ostrza, albo kup brzytwę. Będą znacznie bardziej ekonomiczne zarówno w krótkim, jak i długim okresie.',\n",
       " 'label': 0,\n",
       " 'input_ids': 51985}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\transformers\\training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "\n",
    "# define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"training\",\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_eval_batch_size=24,\n",
    "    per_device_train_batch_size=24\n",
    ")\n",
    "\n",
    "def compute_metric(eval_prediction):\n",
    "    predictions, labels = eval_prediction\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    accuracy = np.mean(predictions == labels)\n",
    "    return {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a27cc071094bef9a76e453349cc0cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/41064 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94eac4f221dc4f3d96c595c884783f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13688 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67718fc83334f2b99bb7c65eed66929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13688 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenizer_fn(batch):\n",
    "    return tokenizer(batch['sentence'], truncation=True, padding=True)\n",
    "\n",
    "tokenized_train = train.map(tokenizer_fn, batched=True)\n",
    "tokenized_eval = eval.map(tokenizer_fn, batched=True)\n",
    "tokenized_test = test.map(tokenizer_fn, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom trainer with weighted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch = None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # compute custom loss (suppose one has 2 labels with different weights)\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 5.0], device=model.device))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adam6\\AppData\\Local\\Temp\\ipykernel_27776\\3114532008.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = CustomTrainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.train(resume_from_checkpoint = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 13688\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Reporting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='95' max='571' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 95/571 00:44 < 03:45, 2.11 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Studia\\NLP\\.venv\\Lib\\site-packages\\transformers\\trainer.py:4076\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   4073\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   4075\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 4076\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4077\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4079\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[0;32m   4080\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[0;32m   4081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4084\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4086\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   4087\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[1;32md:\\Studia\\NLP\\.venv\\Lib\\site-packages\\transformers\\trainer.py:4270\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   4267\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[0;32m   4269\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[1;32m-> 4270\u001b[0m losses, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4271\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4272\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   4273\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4274\u001b[0m )\n",
      "File \u001b[1;32md:\\Studia\\NLP\\.venv\\Lib\\site-packages\\transformers\\trainer.py:4486\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[1;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[0;32m   4484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[0;32m   4485\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 4486\u001b[0m         loss, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   4487\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m   4489\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "Cell \u001b[1;32mIn[19], line 8\u001b[0m, in \u001b[0;36mCustomTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m      6\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# compute custom loss (suppose one has 2 labels with different weights)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m loss_fct \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(weight\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fct(logits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_labels), labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (loss, outputs) \u001b[38;5;28;01mif\u001b[39;00m return_outputs \u001b[38;5;28;01melse\u001b[39;00m loss\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Re-ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find passage candidates using FTS, where the query is the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Elasticsearch(['http://localhost:9200'])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "link = 'http://localhost:9200/'\n",
    "\n",
    "es = Elasticsearch(link)\n",
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_config_lamentizer = {\n",
    "  \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"polish_with_synonyms_with_lam\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "            \"morfologik_stem\",\n",
    "            \"lowercase\"\n",
    "          ]\n",
    "        },\n",
    "        \"polish_with_synonyms_without_lam\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "            \"morfologik_stem\",\n",
    "          ]\n",
    "        },\n",
    "        \"polish_without_synonyms_with_lam\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "            \"lowercase\",\n",
    "          ]\n",
    "        },\n",
    "        \"polish_without_synonyms_without_lam\": {\n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "    }\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"answer_with_synonyms_with_lam\": {\n",
    "        \"type\": \"text\",\n",
    "        \"analyzer\": \"polish_with_synonyms_with_lam\"\n",
    "      },\n",
    "      \"answer_with_synonyms_without_lam\": {\n",
    "        \"type\": \"text\",\n",
    "        \"analyzer\": \"polish_with_synonyms_without_lam\"\n",
    "      },\n",
    "      \"answer_without_synonyms_with_lam\": {\n",
    "        \"type\": \"text\",\n",
    "        \"analyzer\": \"polish_without_synonyms_with_lam\"\n",
    "      },\n",
    "      \"answer_without_synonyms_without_lam\": {\n",
    "        \"type\": \"text\",\n",
    "        \"analyzer\": \"polish_without_synonyms_without_lam\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co jest uważane za wydatek służbowy w podróży służbowej?\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for idx, value  in queries.iterrows():\n",
    "    print(value['text'])\n",
    "    print(value['_id'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'biore_sie_do_roboty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_docs(ds):\n",
    "    for doc in ds:\n",
    "        yield {\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": doc[\"_id\"],\n",
    "            \"_source\": {\n",
    "                \"answer_with_synonyms_with_lam\": doc[\"text\"],\n",
    "                \"answer_with_synonyms_without_lam\": doc[\"text\"],\n",
    "                \"answer_without_synonyms_with_lam\": doc['text'],\n",
    "                \"answer_without_synonyms_without_lam\": doc['text']\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully indexed 57638 documents\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import helpers\n",
    "\n",
    "es.options(ignore_status=[400, 404]).indices.delete(index=index_name)\n",
    "es.indices.create(index=index_name, body=index_config_lamentizer)\n",
    "\n",
    "try:\n",
    "    success, errors = helpers.bulk(es, generate_docs(ds['corpus']))\n",
    "    \n",
    "    print(f\"Successfully indexed {success} documents\")\n",
    "    if errors:\n",
    "        print(f\"Errors during indexing: {errors}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error during bulk indexing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_with_synonyms_with_lam': {},\n",
       " 'answer_with_synonyms_without_lam': {},\n",
       " 'answer_without_synonyms_with_lam': {},\n",
       " 'answer_without_synonyms_without_lam': {}}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_lam_syn = {}\n",
    "\n",
    "indexes_types = [\n",
    "  \"answer_with_synonyms_with_lam\",\n",
    "  \"answer_with_synonyms_without_lam\",\n",
    "  \"answer_without_synonyms_with_lam\",\n",
    "  \"answer_without_synonyms_without_lam\"\n",
    "]\n",
    "for i in indexes_types:\n",
    "  results_lam_syn[i] = {}\n",
    "\n",
    "results_lam_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, value  in queries.iterrows():\n",
    "    query_with_synonyms_with_lam = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"answer_with_synonyms_with_lam\": value['text']\n",
    "            }\n",
    "        },\n",
    "        \"size\": 5\n",
    "    }\n",
    "    query_with_synonyms_without_lam = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"answer_with_synonyms_without_lam\": value['text']\n",
    "            }\n",
    "        },\n",
    "        \"size\": 5\n",
    "    }\n",
    "    query_without_synonyms_with_lam = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"answer_without_synonyms_with_lam\": value['text']\n",
    "            }\n",
    "        },\n",
    "        \"size\": 5\n",
    "    }\n",
    "    query_without_synonyms_without_lam = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"answer_without_synonyms_without_lam\": value['text']\n",
    "            }\n",
    "        },\n",
    "        \"size\": 5\n",
    "    }\n",
    "\n",
    "    queries_temp_list = [query_with_synonyms_with_lam,\n",
    "                         query_with_synonyms_without_lam,\n",
    "                         query_without_synonyms_with_lam,\n",
    "                         query_without_synonyms_without_lam]\n",
    "\n",
    "    for j in range(len(queries_temp_list)):\n",
    "        response = es.search(index=index_name, body=queries_temp_list[j])\n",
    "        response = response['hits']['hits']\n",
    "        temp_list = []\n",
    "        for i in response:\n",
    "            temp_list.append(int(i['_id']))\n",
    "\n",
    "        results_lam_syn[indexes_types[j]][value['_id']] = temp_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_dcg(documents_relevance, k):\n",
    "  sum = 0\n",
    "  for index in range(k):\n",
    "    #need to add another + 1 because python lists starts from 0\n",
    "    sum += documents_relevance[index] / np.log2(index + 1 + 1)\n",
    "\n",
    "  return sum\n",
    "\n",
    "def calculate_ndcg(results, k):\n",
    "  ndcg_list = []\n",
    "  for key, items in results.items():\n",
    "    query = queries[queries['_id'] == key]['text'].iloc[0]\n",
    "    true_relevance = [calculate_true_relevance(query, corpus[corpus['_id'] == str(i)]['text'].iloc[0]) for i in items]\n",
    "    \n",
    "    dcg = calculate_dcg(true_relevance, k)\n",
    "    idcg = calculate_dcg(sorted(true_relevance, reverse=True), k)\n",
    "\n",
    "    ndcg_list.append(0 if dcg == 0 else dcg / idcg)\n",
    "  return np.mean(ndcg_list)\n",
    "\n",
    "def calculate_true_relevance(query, answer):\n",
    "  features = tokenizer(query + separator + answer,  padding=True, truncation=True, return_tensors=\"pt\").to(\"cuda\")\n",
    " \n",
    "  with torch.no_grad():\n",
    "      scores = model(**features).logits\n",
    "      return (scores[0][1] - scores[0][0]).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'„Zwroty wydatków służbowych na ogół nie podlegają opodatkowaniu, ale dojazdy z domu do pracy i z powrotem nie są uważane za podróże służbowe, a jeśli za to płacą, jest to dochód podlegający opodatkowaniu. Nie sądzę, aby carpooling to zmienił, ale jestem nie jest prawnikiem podatkowym ani księgowym. Pozostałe pytania wydają się dotyczyć polityki firmy. Nie ma tu żadnego „powinien”. Nie musisz odbierać innych facetów, ale nie ma obowiązku ich zwrotu mile (lub zatrudnić), więc zastanów się dokładnie nad swoimi priorytetami, zanim się odepchniesz. Nigdy nie przywołuj tego, czego nie możesz odrzucić”.'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[corpus['_id'] == '192843']['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@5 for answer_with_synonyms_with_lam: 0.8943496995792893\n",
      "NDCG@5 for answer_with_synonyms_without_lam: 0.8943496995792893\n",
      "NDCG@5 for answer_without_synonyms_with_lam: 1.0201039155423777\n",
      "NDCG@5 for answer_without_synonyms_without_lam: 1.0201039155423777\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(results_lam_syn)):\n",
    "  result = calculate_ndcg(results_lam_syn[indexes_types[j]], 5)\n",
    "  print(f\"NDCG@5 for {indexes_types[j]}: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do you think simpler methods, like Bayesian bag-of-words model, would work for sentence-pair classification? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that a Bayesian bag-of-words could work. For instance the method can capture patterns in frequencies of words, meaning that word can exist in question and not in answer and the opposite. This way we can have some key words for our sentences. In additon the method would not be that costly as our model. Unfortunelty the method would fall short on understanidng the context of the sentences. In conculsion i think that the method would work especially on small dataset as ours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What hyper-parameters you have selected for the training? What resources (papers, tutorial) you have consulted to select these hyper-parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Think about pros and cons of the neural-network models with respect to natural language processing. Provide at least 2 pros and 2 cons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pros:\n",
    "  - Can understand the context and relatshionship within sentences\n",
    "  - High accuracy \n",
    "- Cons:\n",
    "  - Training such models require powerfull resources\n",
    "  - Neural networks are often considered \"black-box\" models, meaning their decision-making process is difficult to interpret"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
