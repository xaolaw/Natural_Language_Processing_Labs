{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first we load the dataset and gather 1000 sentences like in spacy labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nie jestem r√≥wnie≈º adwokatem ani doradcƒÖ podatkowym. Tak, czynsz, kt√≥ry p≈Çacisz swojemu przyjacielowi, jest dochodem podlegajƒÖcym opodatkowaniu, ale nagle wszelkiego rodzaju wydatki zwiƒÖzane z domem ‚Äì w tym u≈Çamek odsetek zap≈Çaconych od kredytu hipotecznego ‚Äì stajƒÖ siƒô odliczane od podatku. Za≈Ç√≥≈ºmy na przyk≈Çad, ≈ºe kredyt hipoteczny wynosi 1000 z≈Ç miesiƒôcznie, a p≈Çacisz znajomemu 500 z≈Ç miesiƒôcznie. Je≈õli mieszkasz w 50% domu, mo≈ºe on odliczyƒá 50% (plus lub minus) wydatk√≥w zwiƒÖzanych z posiadaniem domu, w tym: Wszystkie te rzeczy (w ka≈ºdym razie 50% z nich) podlegajƒÖ odliczeniu od podatku. By≈Çoby ca≈Çkiem mo≈ºliwe, ≈ºe poni√≥s≈Çby stratƒô na przedsiƒôwziƒôciu i faktycznie co roku obni≈ºa≈Ç podatki. Dop√≥ki nie nadejdzie czas na sprzeda≈º; sprzeda≈º nieruchomo≈õci, kt√≥ra by≈Ça u≈ºywana jako najem, jest bardziej opodatkowana ni≈º sprzeda≈º nieruchomo≈õci, kt√≥ra by≈Ça miejscem zamieszkania.',\n",
       " '‚ÄûJeden scenariusz opisany w pierwotnym pytaniu ‚Äì niewtajemniczony, kt√≥ry handluje po nieformalnych rozmowach ze znajomymi, w kt√≥rych ≈ºadne osoby z wewnƒÖtrz nie korzystajƒÖ bezpo≈õrednio z takiego ujawnienia ‚Äì mo≈ºe nie byƒá nielegalny. (IANAL ‚Äì to tylko moja osobista interpretacja artyku≈Ç√≥w w wiadomo≈õciach ostatnio.) http://www.bloomberg.com/news/articles/2015-10-05/insider-trading-cases-imperiled-as-top-u-s-court-spurns-appeal sƒÖd apelacyjny powiedzia≈Ç prokuratorom musia≈Ç wykazaƒá, ≈ºe osoba ujawniajƒÖca informacje odnios≈Ça wyra≈∫nƒÖ korzy≈õƒá ‚Äì co≈õ wiƒôcej ni≈º pielƒôgnowanie przyja≈∫ni‚Ä¶ W sprawie z 1980 r. SƒÖd Najwy≈ºszy odrzuci≈Ç ideƒô ‚Äûog√≥lnego obowiƒÖzku pomiƒôdzy wszystkimi uczestnikami transakcji rynkowych zaniechania dzia≈Ça≈Ñ na podstawie istotnych, niepublicznych informacji.\"\"\"',\n",
       " 'Narzƒôdzie przesiewowe na FinViz.com pozwoli Ci sprawdziƒá akcje na najni≈ºszym poziomie od 52 tygodni.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(\"clarin-knext/fiqa-pl\", \"corpus\")\n",
    "\n",
    "random.seed(2137)\n",
    "ds_t1000 = []\n",
    "\n",
    "for obj in random.sample(list(ds['corpus']),1000):\n",
    "    ds_t1000.append(obj['text'])\n",
    "\n",
    "ds_t1000[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Installing and running ollama in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use local LLMs, we need to download Ollama. We can do that from [this link](https://ollama.com/download).<br>\n",
    "After installing Ollama, we need to pull our models. For this lab, I have pulled the following models:\n",
    "- gemma2 using `ollama pull gemma2`\n",
    "- phi3:3.8b `ollama pull phi3:3.8b`\n",
    "Both models have paramteres under 10B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can print local models that we downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: gemma2:latest parameter_size: 9.2B\n",
      "model: phi3:3.8b parameter_size: 3.8B\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(\"model: \" + model.model, \"parameter_size: \" + model.details.parameter_size) for model in ollama.list()['models']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, both models have been successfully loaded. For the following tasks, we will exclusively use Gemma-2b to maintain consistency and focus on its specific capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Test model query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our model will answer a basic question always asked in Poland: `DokƒÖd nocƒÖ tupta je≈º?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: zmieniƒá przy zmianie modelu\n",
    "model_name = 'gemma2:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NocƒÖ je≈º tupta **w poszukiwaniu po≈ºywienia**. \n",
      "\n",
      "Je≈ºe sƒÖ g≈Ç√≥wnie nocnymi zwierzƒôtami i wychodzƒÖ z swoich schronisk, aby szukaƒá owad√≥w, ≈õlimak√≥w, robak√≥w i innych ma≈Çych stworze≈Ñ. ü¶îüêõüêå  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "\n",
    "response: ChatResponse = chat(model=model_name, messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'DokƒÖd nocƒÖ tupta je≈º?',\n",
    "    },\n",
    "])\n",
    "\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see our local model works correctly and we can proceed with next tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Comparing Entity Recognition: Spacy vs LLM\n",
    "\n",
    "In this section, we will:\n",
    "1. Identify all entity categories that Spacy recognizes\n",
    "2. Ask our LLM to identify entities in the same text\n",
    "3. Compare the results between Spacy's built-in NER and LLM's entity recognition\n",
    "\n",
    "The spacy examples will be demonstrated using `displacy` for visual entity representation, alongside the direct response from the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) First example zero-shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's load the spacy model and analyze available entites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date', 'geogName', 'orgName', 'persName', 'placeName', 'time']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('pl_core_news_sm') \n",
    "nlp.pipe_labels['ner']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's prepare the sentences for spacy, and randomly choose one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To prawie tak, jakby≈õ *ca≈Çkowicie* siƒô myli≈Ç. Powiedz mi, co Citibank ma co≈õ wsp√≥lnego z JP Morganem. Powiedz mi jeszcze raz, w jaki spos√≥b JP Morgan jest odpowiedzialny za CDO i MBS. Powiedz mi jeszcze raz, jak JP Morgan kosztowa≈Ç podatnik√≥w. Powiedz mi jeszcze raz, jak banki inwestycyjne dokonywa≈Çy inwestycji w oparciu o za≈Ço≈ºenie ‚Äûpodatnicy to pokryjƒÖ‚Äù. Powiedz mi jeszcze raz, jak JP Morgan uprawia≈Ç hazard i musia≈Ç zostaƒá uratowany. Powiedz mi, jak TARP kosztowa≈Ç podatnik√≥w nawet centa. ZdumiewajƒÖce, jak kto≈õ mo≈ºe mieƒá tak silne uczucia do czego≈õ, o czym wiedzƒÖ. Ucz siƒô debilu."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = list(nlp.pipe(ds_t1000))\n",
    "docs[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy's ner has recognize following entites:\n",
    "- persName: Citibank, JP Morganem\n",
    "- orgName: JP Morganem, CDO, MBS, TARP \n",
    "As we can see spacy did not manage to recognize Citibank as orgName, also it recognize JP Morgan as a persName and orgName.<br><br>\n",
    "Now let's see the results of gamma2 llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"pl\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">&quot;To prawie tak, jakby≈õ *ca≈Çkowicie* siƒô myli≈Ç. Powiedz mi, co \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Citibank\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">persName</span>\n",
       "</mark>\n",
       " ma co≈õ wsp√≥lnego z \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    JP Morganem\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">orgName</span>\n",
       "</mark>\n",
       ". Powiedz mi jeszcze raz, w jaki spos√≥b \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    JP Morgan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">persName</span>\n",
       "</mark>\n",
       " jest odpowiedzialny za \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    CDO\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">orgName</span>\n",
       "</mark>\n",
       " i \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    MBS\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">orgName</span>\n",
       "</mark>\n",
       ". Powiedz mi jeszcze raz, jak \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    JP Morgan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">persName</span>\n",
       "</mark>\n",
       " kosztowa≈Ç podatnik√≥w. Powiedz mi jeszcze raz, jak banki inwestycyjne dokonywa≈Çy inwestycji w oparciu o za≈Ço≈ºenie ‚Äûpodatnicy to pokryjƒÖ‚Äù. Powiedz mi jeszcze raz, jak \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    JP Morgan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">persName</span>\n",
       "</mark>\n",
       " uprawia≈Ç hazard i musia≈Ç zostaƒá uratowany. Powiedz mi, jak \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    TARP\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">orgName</span>\n",
       "</mark>\n",
       " kosztowa≈Ç podatnik√≥w nawet centa. ZdumiewajƒÖce, jak kto≈õ mo≈ºe mieƒá tak silne uczucia do czego≈õ, o czym wiedzƒÖ. Ucz siƒô debilu.</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(docs[3], style='ent', page=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define our prompt, we will directly ask model to recognize all entites available in ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_zero = f\"\"\"Odczytaj wszystkie imiona os√≥b, nazwy organizacji,\n",
    "pa≈Ñstw, miejsc, miejsc geograficznych, daty oraz godziny z podanego tekstu. Nastƒôpnie wypisz znalezione s≈Çowa, \n",
    "je≈ºeli wystƒÖpi≈Çy w tek≈õcie, dzielƒÖc je na odpowiednie kategorie. Oto dany tekst: \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gamma model properly recognized orgNames as CitiBank and JP Morgan. It did not assign any entites to CDO (Collateralized Debt Obligation), MBS (mortgage-backed securities) and TARP (Troubled Asset Relief Program????)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"To prawie tak, jakby≈õ *ca≈Çkowicie* siƒô myli≈Ç. Powiedz mi, co Citibank ma co≈õ wsp√≥lnego z JP Morganem. Powiedz mi jeszcze raz, w jaki spos√≥b JP Morgan jest odpowiedzialny za CDO i MBS. Powiedz mi jeszcze raz, jak JP Morgan kosztowa≈Ç podatnik√≥w. Powiedz mi jeszcze raz, jak banki inwestycyjne dokonywa≈Çy inwestycji w oparciu o za≈Ço≈ºenie ‚Äûpodatnicy to pokryjƒÖ‚Äù. Powiedz mi jeszcze raz, jak JP Morgan uprawia≈Ç hazard i musia≈Ç zostaƒá uratowany. Powiedz mi, jak TARP kosztowa≈Ç podatnik√≥w nawet centa. ZdumiewajƒÖce, jak kto≈õ mo≈ºe mieƒá tak silne uczucia do czego≈õ, o czym wiedzƒÖ. Ucz siƒô debilu.\n",
      "## Wykryte elementy tekstu:\n",
      "\n",
      "**Imiona os√≥b:** Nie ma w tekscie nazwisk konkretnych os√≥b.\n",
      "\n",
      "**Nazwy organizacji:**\n",
      "\n",
      "* Citibank\n",
      "* JP Morgan\n",
      "\n",
      "**Pa≈Ñstwa:** Nie ma w tek≈õcie nazw pa≈Ñstw.\n",
      "\n",
      "**Miejsca:** Nie ma w tek≈õcie nazw miejsc.\n",
      "\n",
      "**Miejsca geograficzne:** Nie ma w tek≈õcie nazw miejsc geograficznych.\n",
      "\n",
      "**Daty:** Nie ma w tek≈õcie dat.\n",
      "\n",
      "**Godziny:** Nie ma w tek≈õcie godzin.\n",
      "\n",
      "\n",
      "Let me know if you have any other text you'd like me to analyze! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response: ChatResponse = chat(model=model_name, messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': prompt_zero + ds_t1000[3],\n",
    "    },\n",
    "])\n",
    "\n",
    "print(ds_t1000[3])\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion the first example showed that llm did a better job in recognizing entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Running example few-shot prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As considering the ner nothig will really change so we need to get ourselves a new example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wszystkie rozwiƒÖzania klimatyczne Zapewnia naprawy i us≈Çugi ogrzewania kana≈Çowego w Melbourne. Posiadamy w pe≈Çni wykwalifikowany zesp√≥≈Ç do przeprowadzania dok≈Çadnych i spersonalizowanych napraw i serwisowania szerokiej gamy unikalnych system√≥w grzewczych. Naszym klientom zapewniamy r√≥wnie≈º d≈Çugotrwa≈ÇƒÖ opiekƒô posprzeda≈ºowƒÖ."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can ner recognize correctly Melborune as a placeName, but also Zapewnia as a persName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"pl\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Wszystkie rozwiƒÖzania klimatyczne \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Zapewnia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">persName</span>\n",
       "</mark>\n",
       " naprawy i us≈Çugi ogrzewania kana≈Çowego w \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Melbourne\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">placeName</span>\n",
       "</mark>\n",
       ". Posiadamy w pe≈Çni wykwalifikowany zesp√≥≈Ç do przeprowadzania dok≈Çadnych i spersonalizowanych napraw i serwisowania szerokiej gamy unikalnych system√≥w grzewczych. Naszym klientom zapewniamy r√≥wnie≈º d≈Çugotrwa≈ÇƒÖ opiekƒô posprzeda≈ºowƒÖ.</div>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(docs[10], style='ent', page=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_few = f\"\"\"Odczytaj wszystkie imiona os√≥b (persName), nazwy organizacji (orgName),\n",
    "pa≈Ñstw (placeName), miejsc (placeName), miejsc geograficznych (geogName), daty (date) oraz godziny (time) z podanego tekstu. Nastƒôpnie wypisz znalezione s≈Çowa, \n",
    "je≈ºeli wystƒÖpi≈Çy w tek≈õcie, dzielƒÖc je na odpowiednie kategorie. \n",
    "Przyk≈Çadowo w zdaniu. Adam je≈∫dzi rano autobusem na zajƒôcia NLP w Krakowie na uczelni AGH. Mo≈ºemy znale≈∫ƒá osobƒô: Adam, miejsce geograficznƒô: Krak√≥w, organizacjƒô: AGH.\n",
    "Przyk≈Çadowo w zdaniu. Ostatnie pokolenie blokowa≈Ço wis≈Çostradƒô, wtedy przyjecha≈Ç Stanowski i ich o≈õmieszy≈Ç przed widowaniƒÖ Kana≈Çu ero. Mozemy znale≈∫ƒá \n",
    "osobƒô: Stanowski, miejsce: wis≈Çostardƒô, organizacjƒô: Ostanie pokolenie, kana≈Çu zero\n",
    "Oto dany tekst: \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing ner with a llm, again Melbourne was corectly recognized as a place this time geoPlace. But again the llm had a one screw-up just like ner. It recognized Wszystkie rozwiƒÖzania klimatyczne as a orgName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wszystkie rozwiƒÖzania klimatyczne Zapewnia naprawy i us≈Çugi ogrzewania kana≈Çowego w Melbourne. Posiadamy w pe≈Çni wykwalifikowany zesp√≥≈Ç do przeprowadzania dok≈Çadnych i spersonalizowanych napraw i serwisowania szerokiej gamy unikalnych system√≥w grzewczych. Naszym klientom zapewniamy r√≥wnie≈º d≈Çugotrwa≈ÇƒÖ opiekƒô posprzeda≈ºowƒÖ.\n",
      "## Wykryte s≈Çowa z tekstu:\n",
      "\n",
      "**persName:**  Brak\n",
      "\n",
      "**orgName:** \n",
      "* Wszystkie rozwiƒÖzania klimatyczne\n",
      "\n",
      "**placeName:** Melbourne\n",
      "\n",
      "**placeName:**  Brak\n",
      "\n",
      "**geogName:** Brak\n",
      "\n",
      "**date:**  Brak\n",
      "\n",
      "**time:**  Brak\n",
      "\n",
      "\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "response: ChatResponse = chat(model=model_name, messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': prompt_few + ds_t1000[10],\n",
    "    },\n",
    "])\n",
    "\n",
    "print(ds_t1000[10])\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Running more examples both ner and llm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing sentences. The senteces were chosen randomly of those where ner identified at leadt one entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [docs[15], docs[37], docs[34], docs[666], docs[999]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":-) Kiepski rzƒÖd i ich bezu≈ºyteczne normy bezpiecze≈Ñstwa. Gdyby nie zbyt wiele regulacji, mniej szczƒô≈õliwe czteroosobowe rodziny mog≈Çyby teraz je≈∫dziƒá po dziurawej, pe≈Çnej dziur autostradzie w przetworzonych puszkach ze spamem i zardzewia≈Çymi ig≈Çami bez bezu≈ºytecznego ubezpieczenia samochodowego lub przepis√≥w dotyczƒÖcych emisji.\n",
      "-------\n",
      "Czy sprawdzi≈Çe≈õ merchresearch.com? Ponadto istnieje kilka dodatk√≥w do Chrome, kt√≥re pokazujƒÖ BSR (ocena bestseller√≥w). Nie jestem teraz przy laptopie, ≈ºeby ci je dawaƒá, ale Texas Gal Treasures na YouTube zawsze przeglƒÖda je w swoich streamach, gdzie projektuje koszulkƒô od poczƒÖtku do ko≈Ñca. Mam nadziejƒô ≈ºe to pomo≈ºe!\n",
      "-------\n",
      "20 tys. rocznie na uniwersytet stanowy jest o wiele bardziej wiarygodne (pomijajmy ‚Äûdobre‚Äù, poniewa≈º wtedy musieliby≈õmy uwzglƒôdniƒá rankingi USNWR, a czesne by≈Çoby zdecydowanie wy≈ºsze). Jestem prawie pewien, ≈ºe ≈õrednia czesnego w prywatnej uczelni jest bli≈ºsza 40k/rok, mo≈ºe nawet wiƒôcej.\n",
      "-------\n",
      "Zabrali ju≈º twoje pieniƒÖdze i si≈Çƒô nabywczƒÖ. Bilanse Fedu sƒÖ wype≈Çnione toksycznymi hipotecznymi instrumentami pochodnymi o warto≈õci 4 bilion√≥w dolar√≥w i ameryka≈Ñskimi obligacjami skarbowymi, kt√≥re zosta≈Çy zakupione na najwy≈ºszych obrotach. Przenie≈õ swoje pieniƒÖdze do unii kredytowej.\n",
      "-------\n",
      "**Numer ubezpieczenia spo≈Çecznego** W Stanach Zjednoczonych numer ubezpieczenia spo≈Çecznego (SSN) to dziewiƒôciocyfrowy numer nadawany obywatelom USA, sta≈Çym rezydentom i tymczasowym (pracujƒÖcym) rezydentom zgodnie z sekcjƒÖ 205(c)(2) Ustawa o zabezpieczeniu spo≈Çecznym, skodyfikowana jako 42 U.S.C. ¬ß 405(c)(2). Numer jest nadawany osobie przez Social Security Administration, niezale≈ºnƒÖ agencjƒô rzƒÖdu Stan√≥w Zjednoczonych. Chocia≈º jego g≈Ç√≥wnym celem jest ≈õledzenie os√≥b do cel√≥w zabezpieczenia spo≈Çecznego, numer ubezpieczenia spo≈Çecznego sta≈Ç siƒô de facto krajowym numerem identyfikacyjnym do cel√≥w podatkowych i innych. Numer ubezpieczenia spo≈Çecznego mo≈ºna uzyskaƒá, sk≈ÇadajƒÖc wniosek na formularzu SS-5, Wniosek o kartƒô z numerem ubezpieczenia spo≈Çecznego. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Wyklucz ^me](https://reddit.com/message/compose?to=WikiTextBot&message=Wyklucz ^me&subject=Wyklucz) ^| [^Wyklucz ^z ^subreddit](https://np.reddit.com/r/business/about/banned) ^| [^FAQ ^/ ^Informacje](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^≈πr√≥d≈Ço](https://github.com/kittenswolf/WikiTextBot) ^] ^W d√≥≈Ç ^to ^remove ^| ^v0.27\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for sentence in indexes:\n",
    "  print(sentence)\n",
    "  print(\"-------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ner, let's find all entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts_ner = [{\n",
    "  \"persName\": [],\n",
    "  \"orgName\": [],\n",
    "  \"placeName\": [],\n",
    "  \"geogName\": [],\n",
    "  \"date\": [],\n",
    "  \"time\": []\n",
    "} for _ in range(len(indexes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'persName': ['Kiepski'],\n",
       "  'orgName': [],\n",
       "  'placeName': [],\n",
       "  'geogName': [],\n",
       "  'date': [],\n",
       "  'time': []},\n",
       " {'persName': ['Chrome'],\n",
       "  'orgName': ['BSR'],\n",
       "  'placeName': [],\n",
       "  'geogName': [],\n",
       "  'date': [],\n",
       "  'time': []},\n",
       " {'persName': [],\n",
       "  'orgName': ['USNWR'],\n",
       "  'placeName': [],\n",
       "  'geogName': [],\n",
       "  'date': [],\n",
       "  'time': []},\n",
       " {'persName': [],\n",
       "  'orgName': ['Fedu'],\n",
       "  'placeName': ['ameryka≈Ñskimi'],\n",
       "  'geogName': [],\n",
       "  'date': [],\n",
       "  'time': []},\n",
       " {'persName': ['S.', 'C.', 'Wyklucz'],\n",
       "  'orgName': ['SSN', 'Social Security Administration', 'SS'],\n",
       "  'placeName': ['Stanach Zjednoczonych', 'USA', 'Stan√≥w Zjednoczonych'],\n",
       "  'geogName': [],\n",
       "  'date': [],\n",
       "  'time': []}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, doc in enumerate(indexes):\n",
    "  for ent in doc.ents:\n",
    "    if ent.text not in dicts_ner[i][ent.label_]:    \n",
    "      dicts_ner[i][ent.label_].append(ent.text)\n",
    "dicts_ner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_few = f\"\"\"Odczytaj wszystkie imiona os√≥b (persName), nazwy organizacji (orgName),\n",
    "pa≈Ñstw (placeName), miejsc (placeName), miejsc geograficznych (geogName), daty (date) oraz godziny (time) z podanego tekstu. Nastƒôpnie wypisz znalezione s≈Çowa, \n",
    "je≈ºeli wystƒÖpi≈Çy w tek≈õcie, dzielƒÖc je na odpowiednie kategorie. \n",
    "Przyk≈Çadowo w zdaniu. Adam je≈∫dzi rano autobusem na zajƒôcia NLP w Krakowie na uczelni AGH. Mo≈ºemy znale≈∫ƒá osobƒô: Adam, miejsce geograficznƒô: Krak√≥w, organizacjƒô: AGH.\n",
    "Przyk≈Çadowo w zdaniu. Ostatnie pokolenie blokowa≈Ço wis≈Çostradƒô, wtedy przyjecha≈Ç Stanowski i ich o≈õmieszy≈Ç przed widowaniƒÖ Kana≈Çu ero. Mozemy znale≈∫ƒá \n",
    "osobƒô: Stanowski, miejsce: wis≈Çostardƒô, organizacjƒô: Ostanie pokolenie, kana≈Çu zero.\n",
    "Chcia≈Çbym te≈º aby≈õ odpowiedzi do pytania zapisywa≈Ç w taki spos√≥b persName: [(lista znaleziony imion)] (ma to byƒá object w pythonie gdzie kluczem jes w≈Ça≈õnie persName).\n",
    "Zwr√≥ƒá tylko taki objekt bez zbƒôdnych tekst√≥w, nie u≈ºywaj te≈º nowych lini.\n",
    "Oto dany tekst: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_zero = f\"\"\"Odczytaj wszystkie imiona os√≥b (persName), nazwy organizacji (orgName),\n",
    "pa≈Ñstw (placeName), miejsc (placeName), miejsc geograficznych (geogName), daty (date) oraz godziny (time) z podanego tekstu. Nastƒôpnie wypisz znalezione s≈Çowa, \n",
    "je≈ºeli wystƒÖpi≈Çy w tek≈õcie, dzielƒÖc je na odpowiednie kategorie. Chcia≈Çbym te≈º aby≈õ odpowiedzi do pytania zapisywa≈Ç w taki spos√≥b persName: [(lista znaleziony imion)] (ma to byƒá object w pythonie gdzie kluczem jes w≈Ça≈õnie persName).\n",
    "Zwr√≥ƒá tylko taki objekt bez zbƒôdnych tekst√≥w, nie u≈ºywaj te≈º nowych lini.\n",
    "Oto dany tekst: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "for sentence in indexes:\n",
    "    message = {\n",
    "        'role': 'user',\n",
    "        'content': prompt_few + str(sentence),\n",
    "    }\n",
    "\n",
    "    response: ChatResponse = chat(model=model_name, messages=[message])\n",
    "    messages.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persName: []\n",
      "orgName: ['rzƒÖd']\n",
      "placeName: []\n",
      "geogName: []\n",
      "date: []\n",
      "time: [] \n",
      "\n",
      "persName: ['Texas'] \n",
      "orgName: ['Chrome', 'YouTube', 'merchresearch.com', 'Texas Gal Treasures']\n",
      "placeName: ['Texas']\n",
      "geogName: []\n",
      "date: []\n",
      "time: []  \n",
      "\n",
      "persName: ['Adam', 'Stanowski'],\n",
      "orgName: ['UNSWWR', 'Ostanie pokolenie', 'Kana≈Çu ero'],\n",
      "placeName: [],\n",
      "geogName: ['Krak√≥w'],\n",
      "date: [],\n",
      "time: [] \n",
      "\n",
      "persName: [], \n",
      "orgName: ['Fedu', 'unia kredytowa'],\n",
      "placeName: ['ameryka≈Ñskimi'],\n",
      "geogName: [],\n",
      "date: [],\n",
      "time: []  \n",
      "\n",
      "persName: ['Stanowski']\n",
      "orgName: ['Social Security Administration', 'Ostanie pokolenie', 'Kana≈Çu zero'] \n",
      "placeName: ['Stany Zjednoczonych', 'USA']\n",
      "geogName: ['wis≈Çostradƒô']\n",
      "date: []\n",
      "time: [] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for msg in messages:\n",
    "  print(msg.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts_llm_few = [\n",
    "    {\"persName\": [], \"orgName\": ['rzƒÖd'], \"placeName\": [], \"geogName\": ['autostradzie'], \"date\": [], \"time\": []},\n",
    "    {\"persName\": ['Texas'], \"orgName\": ['Chrome', 'YouTube', 'merchresearch.com', 'Texas Gal Treasures'], \n",
    "     \"placeName\": ['Texas'], \"geogName\": [], \"date\": [], \"time\": []},\n",
    "    {\"persName\": [], \"orgName\": ['USNWR'], \"placeName\": [], \"geogName\": [], \"date\": [], \"time\": []},\n",
    "    {\"persName\": [], \"orgName\": ['Fedu', 'uni Unii kredytowej'], \"placeName\": [], \"geogName\": [], \"date\": [], \"time\": []},\n",
    "    {\"persName\": [], \"orgName\": [\"Social Security Administration\", \"Ustawa o zabezpieczeniu spo≈Çecznym\"], \n",
    "     \"placeName\": [\"Stany Zjednoczone\", \"USA\"], \"geogName\": [], \"date\": [], \"time\": []}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_zero = []\n",
    "for sentence in indexes:\n",
    "    message = {\n",
    "        'role': 'user',\n",
    "        'content': prompt_zero + str(sentence),\n",
    "    }\n",
    "\n",
    "    response: ChatResponse = chat(model=model_name, messages=[message])\n",
    "    messages_zero.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persName: [], orgName: [], placeName: [], geogName: [], date: [], time: []  \n",
      "\n",
      "{'persName': ['Texas Gal'], 'orgName': ['Chrome', 'YouTube', 'merchresearch.com', 'Texas Gal Treasures'], 'placeName': ['Texas'], 'geogName': [], 'date': [], 'time': []} \n",
      "\n",
      "{'persName': [], 'orgName': ['USNWR'], 'placeName': [], 'geogName': [], 'date': [], 'time': []}  \n",
      "\n",
      "{'persName': [], 'orgName': ['Fedu', 'unii kredytowej'], 'placeName': ['ameryka≈Ñskimi'], 'geogName': [], 'date': [], 'time': []} \n",
      "\n",
      "persName: [], orgName: ['Social Security Administration'], placeName: ['Stany Zjednoczone', 'USA'], geogName: [], date: [], time: [] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for msg in messages_zero:\n",
    "  print(msg.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts_llm_zero = [\n",
    "  {'persName': [], 'orgName': ['rzƒÖd'], 'placeName': [], 'geogName': [], 'date': [], 'time': []},\n",
    "  {'persName': ['Texas Gal Treasures'], 'orgName': ['Chrome', 'merchresearch.com', 'YouTube'], 'placeName': ['Texas'], 'geogName': [], 'date': [], 'time': []},\n",
    "  {'persName': [], 'orgName': ['USNWR'], 'placeName': [], 'geogName': [], 'date': [], 'time': []} ,\n",
    "  {'persName': [], 'orgName': ['Fedu', 'uni'], 'placeName': ['ameryka≈Ñskie'], 'geogName': [], 'date': [], 'time': []},\n",
    "  {\"persName\": [],\"orgName\": [\"Social Security Administration\"],\" placeName\": [\"Stany Zjednoczone\", \"USA\"], \"geogName\": [],\"date\": [],\"time\": []} \n",
    "  \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparaing results from ner and llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  :-) Kiepski rzƒÖd i ich bezu≈ºyteczne normy bezpiecze≈Ñstwa. Gdyby nie zbyt wiele regulacji, mniej szczƒô≈õliwe czteroosobowe rodziny mog≈Çyby teraz je≈∫dziƒá po dziurawej, pe≈Çnej dziur autostradzie w przetworzonych puszkach ze spamem i zardzewia≈Çymi ig≈Çami bez bezu≈ºytecznego ubezpieczenia samochodowego lub przepis√≥w dotyczƒÖcych emisji.\n",
      "Ner:  {'persName': ['Kiepski'], 'orgName': [], 'placeName': [], 'geogName': [], 'date': [], 'time': []}\n",
      "LLM few-shot:  {'persName': [], 'orgName': ['rzƒÖd'], 'placeName': [], 'geogName': ['autostradzie'], 'date': [], 'time': []}\n",
      "LLM zero-shot:  {'persName': [], 'orgName': ['rzƒÖd'], 'placeName': [], 'geogName': [], 'date': [], 'time': []}\n",
      "--------------\n",
      "Sentence:  Czy sprawdzi≈Çe≈õ merchresearch.com? Ponadto istnieje kilka dodatk√≥w do Chrome, kt√≥re pokazujƒÖ BSR (ocena bestseller√≥w). Nie jestem teraz przy laptopie, ≈ºeby ci je dawaƒá, ale Texas Gal Treasures na YouTube zawsze przeglƒÖda je w swoich streamach, gdzie projektuje koszulkƒô od poczƒÖtku do ko≈Ñca. Mam nadziejƒô ≈ºe to pomo≈ºe!\n",
      "Ner:  {'persName': ['Chrome'], 'orgName': ['BSR'], 'placeName': [], 'geogName': [], 'date': [], 'time': []}\n",
      "LLM few-shot:  {'persName': ['Texas'], 'orgName': ['Chrome', 'YouTube', 'merchresearch.com', 'Texas Gal Treasures'], 'placeName': ['Texas'], 'geogName': [], 'date': [], 'time': []}\n",
      "LLM zero-shot:  {'persName': ['Texas Gal Treasures'], 'orgName': ['Chrome', 'merchresearch.com', 'YouTube'], 'placeName': ['Texas'], 'geogName': [], 'date': [], 'time': []}\n",
      "--------------\n",
      "Sentence:  20 tys. rocznie na uniwersytet stanowy jest o wiele bardziej wiarygodne (pomijajmy ‚Äûdobre‚Äù, poniewa≈º wtedy musieliby≈õmy uwzglƒôdniƒá rankingi USNWR, a czesne by≈Çoby zdecydowanie wy≈ºsze). Jestem prawie pewien, ≈ºe ≈õrednia czesnego w prywatnej uczelni jest bli≈ºsza 40k/rok, mo≈ºe nawet wiƒôcej.\n",
      "Ner:  {'persName': [], 'orgName': ['USNWR'], 'placeName': [], 'geogName': [], 'date': [], 'time': []}\n",
      "LLM few-shot:  {'persName': [], 'orgName': ['USNWR'], 'placeName': [], 'geogName': [], 'date': [], 'time': []}\n",
      "LLM zero-shot:  {'persName': [], 'orgName': ['USNWR'], 'placeName': [], 'geogName': [], 'date': [], 'time': []}\n",
      "--------------\n",
      "Sentence:  Zabrali ju≈º twoje pieniƒÖdze i si≈Çƒô nabywczƒÖ. Bilanse Fedu sƒÖ wype≈Çnione toksycznymi hipotecznymi instrumentami pochodnymi o warto≈õci 4 bilion√≥w dolar√≥w i ameryka≈Ñskimi obligacjami skarbowymi, kt√≥re zosta≈Çy zakupione na najwy≈ºszych obrotach. Przenie≈õ swoje pieniƒÖdze do unii kredytowej.\n",
      "Ner:  {'persName': [], 'orgName': ['Fedu'], 'placeName': ['ameryka≈Ñskimi'], 'geogName': [], 'date': [], 'time': []}\n",
      "LLM few-shot:  {'persName': [], 'orgName': ['Fedu', 'uni Unii kredytowej'], 'placeName': [], 'geogName': [], 'date': [], 'time': []}\n",
      "LLM zero-shot:  {'persName': [], 'orgName': ['Fedu', 'uni'], 'placeName': ['ameryka≈Ñskie'], 'geogName': [], 'date': [], 'time': []}\n",
      "--------------\n",
      "Sentence:  **Numer ubezpieczenia spo≈Çecznego** W Stanach Zjednoczonych numer ubezpieczenia spo≈Çecznego (SSN) to dziewiƒôciocyfrowy numer nadawany obywatelom USA, sta≈Çym rezydentom i tymczasowym (pracujƒÖcym) rezydentom zgodnie z sekcjƒÖ 205(c)(2) Ustawa o zabezpieczeniu spo≈Çecznym, skodyfikowana jako 42 U.S.C. ¬ß 405(c)(2). Numer jest nadawany osobie przez Social Security Administration, niezale≈ºnƒÖ agencjƒô rzƒÖdu Stan√≥w Zjednoczonych. Chocia≈º jego g≈Ç√≥wnym celem jest ≈õledzenie os√≥b do cel√≥w zabezpieczenia spo≈Çecznego, numer ubezpieczenia spo≈Çecznego sta≈Ç siƒô de facto krajowym numerem identyfikacyjnym do cel√≥w podatkowych i innych. Numer ubezpieczenia spo≈Çecznego mo≈ºna uzyskaƒá, sk≈ÇadajƒÖc wniosek na formularzu SS-5, Wniosek o kartƒô z numerem ubezpieczenia spo≈Çecznego. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Wyklucz ^me](https://reddit.com/message/compose?to=WikiTextBot&message=Wyklucz ^me&subject=Wyklucz) ^| [^Wyklucz ^z ^subreddit](https://np.reddit.com/r/business/about/banned) ^| [^FAQ ^/ ^Informacje](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^≈πr√≥d≈Ço](https://github.com/kittenswolf/WikiTextBot) ^] ^W d√≥≈Ç ^to ^remove ^| ^v0.27\n",
      "Ner:  {'persName': ['S.', 'C.', 'Wyklucz'], 'orgName': ['SSN', 'Social Security Administration', 'SS'], 'placeName': ['Stanach Zjednoczonych', 'USA', 'Stan√≥w Zjednoczonych'], 'geogName': [], 'date': [], 'time': []}\n",
      "LLM few-shot:  {'persName': [], 'orgName': ['Social Security Administration', 'Ustawa o zabezpieczeniu spo≈Çecznym'], 'placeName': ['Stany Zjednoczone', 'USA'], 'geogName': [], 'date': [], 'time': []}\n",
      "LLM zero-shot:  {'persName': [], 'orgName': ['Social Security Administration'], ' placeName': ['Stany Zjednoczone', 'USA'], 'geogName': [], 'date': [], 'time': []}\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for i, (ner, llm_f, llm_z) in enumerate(zip(dicts_ner, dicts_llm_few, dicts_llm_zero)):\n",
    "    print(\"Sentence: \", indexes[i])\n",
    "    print(\"Ner: \", ner)\n",
    "    print(\"LLM few-shot: \", llm_f)\n",
    "    print(\"LLM zero-shot: \", llm_z)\n",
    "    print(\"--------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there was only one sentence where both llm prompts and ner got the same result (3rd sentence). Comparing all results we can see that Llm with a few-shot prompt gather more correct information. Although looking at the last example (5th sentence) the zero-shot version corectly did not put `Ustawa (...)` as orgName. Overall ner classifies much more information but uncorectly. <br>\n",
    "Funny thing in 2nd sentence ner classified `Chrome` as persName while LLM zero classifed `Texas Gal Treasures` as name but also classifed `Texas` as placeName.\n",
    "Searching through web `Texas` is indeed a person name \"The name Texas is primarily a gender-neutral name of Native American - Caddo origin that means Friend.\" \n",
    "[source link of the name](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjfrY_amqiKAxVnJRAIHfAhBHUQFnoECBAQAw&url=https%3A%2F%2Fbabynames.com%2Fname%2Ftexas&usg=AOvVaw0nCGZu-cmPCFjKU32rP72X&opi=89978449)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Building a simple evaluation pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's calculate the metrics `recall`,`f1-score`,`precision` for NER method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our dataset, prepared by students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Niemal dwa tygodnie temu dosz≈Ço do walki, na k...</td>\n",
       "      <td>[('Jake Paul', 'persName', (119, 128)), (\"Mike...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Te problemy widaƒá ju≈º na poczƒÖtku. Ridley Scot...</td>\n",
       "      <td>[('Ridley Scott', 'persName', (35, 47)), ('Aca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phoenix Suns po dobrym starcie sezonu ostatnio...</td>\n",
       "      <td>[('Phoenix Suns', 'orgName', (0, 12)), ('Arizo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O≈õwiadczenie Karola Nawrockiego: Szef Instytut...</td>\n",
       "      <td>[('Karola Nawrockiego', 'persName', (13, 31)),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brandin Podziemski wystƒôpuje w Golden State Wa...</td>\n",
       "      <td>[('Brandin Podziemski', 'persName', (0, 18)), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  Niemal dwa tygodnie temu dosz≈Ço do walki, na k...   \n",
       "1  Te problemy widaƒá ju≈º na poczƒÖtku. Ridley Scot...   \n",
       "2  Phoenix Suns po dobrym starcie sezonu ostatnio...   \n",
       "3  O≈õwiadczenie Karola Nawrockiego: Szef Instytut...   \n",
       "4  Brandin Podziemski wystƒôpuje w Golden State Wa...   \n",
       "\n",
       "                                            Entities  \n",
       "0  [('Jake Paul', 'persName', (119, 128)), (\"Mike...  \n",
       "1  [('Ridley Scott', 'persName', (35, 47)), ('Aca...  \n",
       "2  [('Phoenix Suns', 'orgName', (0, 12)), ('Arizo...  \n",
       "3  [('Karola Nawrockiego', 'persName', (13, 31)),...  \n",
       "4  [('Brandin Podziemski', 'persName', (0, 18)), ...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file_path = '../data/lab7_input.csv'  \n",
    "df = pd.read_csv(csv_file_path, sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the Entities column is semi designed for Scorer from spacy, let's see one record. As we can see We have 3 values in Entiteis the word, entity and place in string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(\"Jan Pawe≈Ç 2\",\"persName\",(0,11)),(\"Polski\",\"placeName\",(39,45)),(\"Watykanie\",\"placeName\",(61,70))]\n",
      "Jan Pawe≈Ç 2 by≈Ç papie≈ºem pochodzƒÖcym z Polski, urzƒôdujacym w Watykanie.\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[-3]['Entities'])\n",
    "print(df.iloc[-3]['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create a new entities list for spacy Scorer, every item should have a begining (where word starts), end (where word ends), entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(119, 128, 'persName'),\n",
       " (137, 150, 'persName'),\n",
       " (297, 315, 'persName'),\n",
       " (83, 95, 'orgName'),\n",
       " (98, 107, 'placeName'),\n",
       " (110, 118, 'placeName')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "entities = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "  entities_list = ast.literal_eval(row['Entities'])\n",
    "  entities.append([(ent[2][0], ent[2][1], ent[1]) for ent in entities_list])\n",
    "  \n",
    "entities[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the Scorer and calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.training import Example\n",
    "from spacy.scorer import Scorer\n",
    "\n",
    "\n",
    "examples = []\n",
    "\n",
    "def evaluate(ner_model, df, entities):\n",
    "    \n",
    "    scorer = Scorer()\n",
    "\n",
    "    for (index, row), annot in zip(df.iterrows(), entities):\n",
    "        text = row['Text']\n",
    "        doc = ner_model.make_doc(text)\n",
    "        example = Example.from_dict(doc, {\"entities\": annot})\n",
    "        example.predicted = nlp(str(example.predicted))\n",
    "        examples.append(example)\n",
    "        #print(spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), annot))\n",
    "    score = scorer.score(examples)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"W≈Çasny komitet i rozdawanie pieniƒôdzy: Wiƒôkszo≈õƒá ≈õ...\" with entities \"[(86, 91, 'persName'), (101, 112, 'orgName'), (161...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Zwyciƒôstwo Donalda Trumpa w wyborach prezydenckich...\" with entities \"[(11, 25, 'persName'), (53, 56, 'placeName'), (130...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Prezydent Korei Po≈Çudniowej Jun Suk Jeol otrzyma≈Ç ...\" with entities \"[(10, 27, 'placeName'), (28, 40, 'persName'), (140...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Wolfgang Fink jest szefem niemieckiego oddzia≈Çu Go...\" with entities \"[(0, 13, 'persName'), (26, 38, 'placeName'), (48, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Na madryckim lotnisku Barajas rozpoczƒÖ≈Ç siƒô we wto...\" with entities \"[(23, 30, 'placeName'), (48, 54, 'date'), (181, 19...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"W Malibu niedaleko Los Angeles szaleje po≈ºar, kt√≥r...\" with entities \"[(3, 9, 'placeName'), (20, 31, 'orgName')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Agencja Reuters opublikowa≈Ça zdjƒôcia satelitarne, ...\" with entities \"[(9, 16, 'orgName'), (108, 114, 'placeName'), (135...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"W niekt√≥rych regionach Chorwacji ≈õnieg sypa≈Ç od ni...\" with entities \"[(24, 33, 'placeName'), (49, 58, 'date')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"W Australii wymierajƒÖ w zastraszajƒÖcym tempie bezk...\" with entities \"[(3, 12, 'placeName'), (110, 115, 'date')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Tej nocy oraz w ≈õrodƒô rano zimowa aura bƒôdzie zagr...\" with entities \"[(77, 83, 'placeName'), (85, 126, 'orgName')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Czy tej zimy na Pacyfiku pojawi siƒô La Nina? Jak w...\" with entities \"[(17, 25, 'geogName'), (65, 100, 'orgName')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Rok 2024 najprawdopodobniej bƒôdzie najcieplejszy w...\" with entities \"[(5, 9, 'date'), (156, 166, 'orgName')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"≈öci≈õle chroniony gatunek czarnej pszczo≈Çy zaobserw...\" with entities \"[(69, 95, 'orgName'), (150, 156, 'placeName')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Premier Donald Tusk zapowiedzia≈Ç, ≈ºe Polska bƒôdzie...\" with entities \"[(9, 20, 'persName'), (38, 44, 'placeName'), (96, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Przyw√≥dca Bia≈Çorusi Aleksandr ≈Åukaszenko w czasie ...\" with entities \"[(11, 20, 'placeName'), (21, 41, 'persName'), (77,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Ubieg≈Çej nocy izraelska marynarka wojenna mia≈Ça pr...\" with entities \"[(158, 171, 'persName'), (182, 197, 'orgName')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Premier Izraela Beniamin Netanjahu o≈õwiadczy≈Ç, ≈ºe ...\" with entities \"[(9, 16, 'placeName'), (17, 35, 'persName'), (67, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Prognozowana d≈Çugo≈õƒá ≈ºycia Amerykan√≥w niepokoi nau...\" with entities \"[(62, 66, 'date'), (72, 89, 'placeName')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Iga ≈öwiƒÖtek poprowadzi≈Ça reprezentacjƒô Polski do h...\" with entities \"[(1, 12, 'persName'), (40, 46, 'placeName'), (74, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Tu≈º przed meczem Ligi Mistrz√≥w z BorussiƒÖ Dortmund...\" with entities \"[(18, 31, 'orgName'), (34, 51, 'orgName'), (52, 62...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"W nocy z 21 na 22 grudnia w stolicy Arabii Saudyjs...\" with entities \"[(10, 26, 'date'), (37, 55, 'placeName'), (58, 66,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Australijski tenisista Nick Kyrgios jest jednƒÖ z n...\" with entities \"[(24, 36, 'persName'), (103, 118, 'persName'), (12...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Sebastian Chmara zosta≈Ç wybrany nowym prezesem Pol...\" with entities \"[(1, 17, 'persName'), (48, 82, 'orgName'), (99, 12...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Chainsaw Man opowiada historiƒô Denjiego, ≈Çowcy dem...\" with entities \"[(0, 12, 'persName'), (31, 39, 'persName'), (71, 7...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\Studia\\NLP\\.venv\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Amazon jest firmƒÖ prowadzonƒÖ przez Jeff Bezosa i j...\" with entities \"[(0, 7, 'orgName'), (36, 46, 'persName'), (169, 17...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score = evaluate(nlp, df, entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see below the average precision of all values is not that great 0.48. Looking at every Entity, we can see the reason date or time have really low values there. Looking at Recall we can see that it's value is highre than precision which means ner tends to over-identify entities. Looking through every entitiy we can see that placeName had the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Precision: 48.0%\n",
      "Overall Recall: 56.99999999999999%\n",
      "Overall F1 Score: 52.0%\n",
      "Entity Type: placeName\n",
      "  Precision: 54.0%\n",
      "  Recall: 73.0%\n",
      "  F1 Score: 62.0%\n",
      "Entity Type: geogName\n",
      "  Precision: 15.0%\n",
      "  Recall: 40.0%\n",
      "  F1 Score: 22.0%\n",
      "Entity Type: persName\n",
      "  Precision: 46.0%\n",
      "  Recall: 67.0%\n",
      "  F1 Score: 54.0%\n",
      "Entity Type: orgName\n",
      "  Precision: 60.0%\n",
      "  Recall: 43.0%\n",
      "  F1 Score: 50.0%\n",
      "Entity Type: date\n",
      "  Precision: 17.0%\n",
      "  Recall: 28.999999999999996%\n",
      "  F1 Score: 21.0%\n",
      "Entity Type: time\n",
      "  Precision: 0.0%\n",
      "  Recall: 0.0%\n",
      "  F1 Score: 0.0%\n"
     ]
    }
   ],
   "source": [
    "precision = score[\"ents_p\"]\n",
    "recall = score[\"ents_r\"]\n",
    "f1_score = score[\"ents_f\"]\n",
    "\n",
    "print(f\"Overall Precision: {round(precision, 2) * 100}%\")\n",
    "print(f\"Overall Recall: {round(recall, 2)* 100}%\")\n",
    "print(f\"Overall F1 Score: {round(f1_score,2)* 100}%\")\n",
    "\n",
    "for entity, metrics in score[\"ents_per_type\"].items():\n",
    "    print(f\"Entity Type: {entity}\")\n",
    "    print(f\"  Precision: {round(metrics['p'],2)* 100}%\")\n",
    "    print(f\"  Recall: {round(metrics['r'],2)* 100}%\")\n",
    "    print(f\"  F1 Score: {round(metrics['f'],2)* 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the same prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_few_score = f\"\"\"Odczytaj wszystkie imiona os√≥b (persName), nazwy organizacji (orgName),\n",
    "pa≈Ñstw (placeName), miejsc (placeName), miejsc geograficznych (geogName), daty (date) oraz godziny (time) z podanego tekstu. Nastƒôpnie wypisz znalezione s≈Çowa, \n",
    "je≈ºeli wystƒÖpi≈Çy w tek≈õcie, dzielƒÖc je na odpowiednie kategorie. \n",
    "Przyk≈Çadowo w zdaniu. Adam je≈∫dzi rano autobusem na zajƒôcia NLP w Krakowie na uczelni AGH. Mo≈ºemy znale≈∫ƒá osobƒô: Adam, miejsce geograficznƒô: Krak√≥w, organizacjƒô: AGH.\n",
    "Przyk≈Çadowo w zdaniu. Ostatnie pokolenie blokowa≈Ço wis≈Çostradƒô, wtedy przyjecha≈Ç Stanowski i ich o≈õmieszy≈Ç przed widowaniƒÖ Kana≈Çu ero. Mozemy znale≈∫ƒá \n",
    "osobƒô: Stanowski, miejsce: wis≈Çostardƒô, organizacjƒô: Ostanie pokolenie, kana≈Çu zero.\n",
    "Chcia≈Çbym te≈º aby≈õ odpowiedzi do pytania zapisywa≈Ç w taki spos√≥b persName: [(lista znaleziony imion)] (ma to byƒá object w pythonie gdzie kluczem jes w≈Ça≈õnie persName).\n",
    "Zwr√≥ƒá tylko taki objekt bez zbƒôdnych tekst√≥w, nie u≈ºywaj te≈º nowych lini.\n",
    "Oto dany tekst: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_score = []\n",
    "for index, sentence in df.iterrows():\n",
    "    message = {\n",
    "        'role': 'user',\n",
    "        'content': prompt_few_score + str(sentence),\n",
    "    }\n",
    "\n",
    "    response: ChatResponse = chat(model=model_name, messages=[message])\n",
    "    messages_score.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the output to file, although llm returns data as python objects sometimes it adds additional text so I need to fix that by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/lab7_llm_output.txt', \"w\", encoding=\"utf-8\") as file:\n",
    "    file.writelines([line.message.content + \"\\n\" for line in messages_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'persName': ['Jan Pawe≈Ç 2']}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_ = '../data/lab7_llm_output.txt'\n",
    "\n",
    "llm_outputs = []\n",
    "with open(path_, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        if line.strip():\n",
    "            try:\n",
    "                obj = eval(line.strip())\n",
    "                llm_outputs.append(obj)\n",
    "            except:\n",
    "                continue\n",
    "llm_outputs[-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the the True values in list of python objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'persName': ['Jan Pawe≈Ç 2'],\n",
       " 'orgName': [],\n",
       " 'placeName': ['Polski', 'Watykanie'],\n",
       " 'geogName': [],\n",
       " 'date': [],\n",
       " 'time': []}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_llm = [{\n",
    "  \"persName\": [],\n",
    "  \"orgName\": [],\n",
    "  \"placeName\": [],\n",
    "  \"geogName\": [],\n",
    "  \"date\": [],\n",
    "  \"time\": []\n",
    "} for _ in range(len(entities))]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "  entities_list = ast.literal_eval(row['Entities'])\n",
    "  for ent in entities_list:\n",
    "    entities_llm[index][ent[1]].append(ent[0])\n",
    "  \n",
    "entities_llm[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_obj = {\n",
    "  'persName': {\n",
    "    'True': 0,\n",
    "    'False': 0\n",
    "  },\n",
    "  'orgName': {\n",
    "    'True': 0,\n",
    "    'False': 0\n",
    "  },\n",
    "  'geogName': {\n",
    "    'True': 0,\n",
    "    'False': 0\n",
    "  },\n",
    "  'date': {\n",
    "    'True': 0,\n",
    "    'False': 0\n",
    "  },\n",
    "  'time': {\n",
    "    'True': 0,\n",
    "    'False': 0\n",
    "  },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the metrics for llm. As we can see the llm result are much better than ner. Overall precision sits at 77.69% while ner's was 48.0%. The llm method did much more better job than ner especially in time and date field. The llm is conservative in its predictions - when it identifies entities, it's usually correct, but misses many entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "persName:\n",
      "Precision: 88.89%\n",
      "Recall: 40.00%\n",
      "F1 Score: 55.17%\n",
      "\n",
      "orgName:\n",
      "Precision: 62.50%\n",
      "Recall: 19.23%\n",
      "F1 Score: 29.41%\n",
      "\n",
      "geogName:\n",
      "Precision: 80.00%\n",
      "Recall: 28.57%\n",
      "F1 Score: 42.11%\n",
      "\n",
      "date:\n",
      "Precision: 83.33%\n",
      "Recall: 35.71%\n",
      "F1 Score: 50.00%\n",
      "\n",
      "time:\n",
      "Precision: 100.00%\n",
      "Recall: 100.00%\n",
      "F1 Score: 100.00%\n",
      "\n",
      "OVERALL METRICS:\n",
      "Precision: 77.69%\n",
      "Recall: 29.38%\n",
      "F1 Score: 42.63%\n"
     ]
    }
   ],
   "source": [
    "total_tp = 0\n",
    "total_fp = 0\n",
    "total_fn = 0\n",
    "\n",
    "metrics = {'overall': {}, 'entities': {}}\n",
    "\n",
    "for entity_type, counts in result_obj.items():\n",
    "    true_positives = counts['True']\n",
    "    false_negatives = counts['False']\n",
    "    false_positives = 0\n",
    "    \n",
    "    for pred in llm_outputs:\n",
    "        pred_entities = set(pred.get(entity_type, []))\n",
    "        gold_entities = set(entities_llm[llm_outputs.index(pred)][entity_type])\n",
    "        false_positives += len(pred_entities - gold_entities)\n",
    "\n",
    "    total_tp += true_positives\n",
    "    total_fp += false_positives\n",
    "    total_fn += false_negatives\n",
    "\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    metrics['entities'][entity_type] = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "    print(f\"\\n{entity_type}:\")\n",
    "    print(f\"Precision: {precision:.2%}\")\n",
    "    print(f\"Recall: {recall:.2%}\")\n",
    "    print(f\"F1 Score: {f1:.2%}\")\n",
    "\n",
    "overall_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
    "overall_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
    "overall_f1 = 2 * (overall_precision * overall_recall) / (overall_precision + overall_recall) if (overall_precision + overall_recall) > 0 else 0\n",
    "\n",
    "metrics['overall'] = {\n",
    "    'precision': overall_precision,\n",
    "    'recall': overall_recall,\n",
    "    'f1': overall_f1\n",
    "}\n",
    "\n",
    "print(\"\\nOVERALL METRICS:\")\n",
    "print(f\"Precision: {overall_precision:.2%}\")\n",
    "print(f\"Recall: {overall_recall:.2%}\")\n",
    "print(f\"F1 Score: {overall_f1:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Answering questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does the performance of LLM-based NER compare to traditional approaches? What are the trade-offs in terms of accuracy, speed, and resource usage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The llm method was more precise but also it took 10 minutes to calculate all results. Also ner model is not nearly as big as llm to store. NER results were much more worse than LLM's when we made our tests. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which prompting strategy proved most effective for NER and classification tasks? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The few-shot method proved itself being better than zero method. I think that a few examples provided enough to make it recognize more companies or people names. In conlusion to prompts the bigger the better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the limitations and potential biases of using LLMs for NER and classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The limitations definitely include the significant computational resources required to process all the messages sent to an LLM. Regarding potential biases, the training data used to develop an LLM can be problematic if it does not include names of people from diverse countries or geographical regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In what scenarios would you recommend using traditional NER vs. LLM-based approaches?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NER:\n",
    "- very usefull for big data does not need as much resources as llm\n",
    "- Working with one language\n",
    "- When entities are well defined\n",
    "\n",
    "LLM:\n",
    "- Dealing with complex entities\n",
    "- When acccuracy is more important than speed\n",
    "- Working with words from diffrent languages, for example polish sentence using english words="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
